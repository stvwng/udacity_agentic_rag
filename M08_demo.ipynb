{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796124ec",
   "metadata": {},
   "source": [
    "# Module 08: Agentic RAG\n",
    "This notebook demonstrates how traditional Chroma DB works for RAG pipelines.\n",
    "\n",
    "## What we'll learn:\n",
    "- ChromaDB\n",
    "- OpenAI Embeddings\n",
    "- RAG using State Machine\n",
    "- Retrieval, Augment and Generation as steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da7e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca83ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models.Collection import Collection\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.llm import LLM\n",
    "from lib.messages import BaseMessage, UserMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c4424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('pdfminer').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2744c74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "]\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7858167",
   "metadata": {},
   "source": [
    "## ChromaDB with Default Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75924db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4d5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e79ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26202218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1'],\n",
       " 'embeddings': array([[ 6.06747121e-02, -3.51287387e-02,  6.06430210e-02,\n",
       "         -5.11958823e-02,  1.13577358e-01, -1.88812558e-02,\n",
       "         -2.68563069e-02,  5.48521988e-02,  3.23705971e-02,\n",
       "          5.42319790e-02, -4.04220782e-02, -1.90565046e-02,\n",
       "         -5.98006099e-02,  2.56025922e-02,  8.48477483e-02,\n",
       "          4.12208885e-02,  3.95124070e-02, -4.00038101e-02,\n",
       "         -7.66580924e-02,  2.78269649e-02,  5.38381748e-02,\n",
       "         -1.35235973e-02,  9.65652838e-02, -3.04286182e-02,\n",
       "          6.62264926e-03,  7.21764490e-02, -9.53955278e-02,\n",
       "         -2.75929421e-02,  7.86578842e-03, -6.68484047e-02,\n",
       "         -1.27422102e-02,  1.21331684e-01, -6.66161552e-02,\n",
       "         -3.28697823e-02, -6.49218261e-02, -1.61951613e-02,\n",
       "         -3.33233248e-03,  8.04133341e-02, -3.84463109e-02,\n",
       "          1.44819714e-04,  3.71691165e-03,  4.83801402e-02,\n",
       "         -8.19774050e-06, -4.51294743e-02, -1.37413908e-02,\n",
       "         -7.15169311e-02,  1.01871518e-02, -4.22974639e-02,\n",
       "          3.16687077e-02,  1.55995348e-02, -3.98045108e-02,\n",
       "         -5.78884557e-02, -6.40821084e-03,  5.05174100e-02,\n",
       "          1.33637050e-02, -6.78867027e-02,  1.05835916e-02,\n",
       "         -4.71956246e-02,  2.76528508e-03,  6.26844093e-02,\n",
       "          3.98131758e-02,  2.90585775e-03, -1.10588446e-02,\n",
       "         -3.56718525e-02,  1.66201249e-01,  2.22128256e-05,\n",
       "         -9.47574433e-03, -1.11346409e-01,  2.19913963e-02,\n",
       "         -5.18135168e-02, -1.24024006e-03, -1.01792952e-02,\n",
       "          2.69685499e-02,  4.42338809e-02, -6.56521544e-02,\n",
       "          3.83608416e-02,  4.76819016e-02, -3.88570651e-02,\n",
       "          6.39514849e-02,  2.61537675e-02,  1.20889463e-01,\n",
       "         -9.07477457e-03, -3.85720916e-02,  2.28272900e-02,\n",
       "          5.07812761e-03, -1.89832430e-02, -2.87891477e-02,\n",
       "         -5.56440279e-02, -8.61207396e-03,  5.86220529e-03,\n",
       "          5.63710332e-02,  6.81066886e-03,  4.91664223e-02,\n",
       "          1.10518306e-01, -3.60299274e-02, -2.38153189e-02,\n",
       "         -1.63002610e-02, -3.64670530e-02, -3.18391062e-02,\n",
       "          8.61841217e-02,  3.62210311e-02, -8.32590461e-02,\n",
       "         -3.95168774e-02, -3.89860221e-03,  6.57967106e-03,\n",
       "         -5.79288788e-02,  7.79322535e-02, -2.28347518e-02,\n",
       "         -5.00371419e-02,  6.03736937e-03, -8.09206907e-03,\n",
       "          4.45700437e-02,  4.16007359e-03,  4.67487760e-02,\n",
       "         -4.04267497e-02,  7.59727657e-02,  3.34772840e-02,\n",
       "          2.89932266e-02,  2.71295253e-02,  1.18457219e-02,\n",
       "         -5.04872836e-02, -4.75715064e-02,  4.13293578e-02,\n",
       "         -1.27797686e-02,  9.69001725e-02, -3.82200778e-02,\n",
       "         -8.40006098e-02, -2.62859675e-33,  2.09687073e-02,\n",
       "         -2.21679593e-03, -3.44058424e-02,  3.05759441e-02,\n",
       "          1.03627414e-01, -4.35053445e-02, -2.39885002e-02,\n",
       "          1.93823129e-02, -4.34545018e-02, -4.16008234e-02,\n",
       "         -4.09101136e-02,  1.49101065e-02, -5.59177324e-02,\n",
       "          8.51399079e-02, -5.82279358e-03, -6.91416413e-02,\n",
       "          2.26514116e-02, -4.11390215e-02,  4.50249501e-02,\n",
       "         -5.11237830e-02,  7.75611177e-02,  1.48914196e-02,\n",
       "         -1.96254114e-03,  3.21949832e-02, -6.81356043e-02,\n",
       "          1.49354324e-01,  5.72875515e-02, -1.83696747e-02,\n",
       "          2.91911867e-02,  7.61174485e-02, -1.02901936e-01,\n",
       "         -7.13402545e-03,  3.35546210e-02,  3.48361097e-02,\n",
       "         -1.31943682e-03,  2.54373206e-03, -4.71428521e-02,\n",
       "          2.60298587e-02, -3.65439095e-02, -3.68587784e-02,\n",
       "         -2.72801961e-03,  2.17596646e-02, -1.12907723e-01,\n",
       "         -2.99254116e-02, -2.38830578e-02, -6.51488528e-02,\n",
       "          1.16826897e-03,  1.92673281e-02, -1.62135307e-02,\n",
       "          2.74846889e-02,  5.08467630e-02,  2.73126923e-02,\n",
       "         -2.71699484e-02,  3.59348170e-02, -5.81000634e-02,\n",
       "         -2.63191070e-02,  8.34281277e-03, -2.87807938e-02,\n",
       "          5.10897823e-02,  2.35921331e-02,  1.05956458e-02,\n",
       "         -3.48916575e-02, -2.97328904e-02,  6.21747598e-02,\n",
       "          4.96853702e-02,  2.55106995e-03, -6.38423441e-03,\n",
       "         -1.16780680e-02, -2.02062894e-02, -1.37649486e-02,\n",
       "         -4.81273001e-03,  5.53648584e-02,  9.78615042e-03,\n",
       "         -7.64169842e-02, -7.46832937e-02, -7.68514276e-02,\n",
       "         -1.85880903e-02,  2.21682107e-03,  6.74633458e-02,\n",
       "          2.58894311e-03,  1.15040848e-02,  8.59635621e-02,\n",
       "          1.95179740e-03, -2.49777474e-02, -1.21807130e-02,\n",
       "         -9.39458143e-03,  5.22444099e-02, -6.60065711e-02,\n",
       "         -5.23892120e-02, -1.49614569e-02,  5.78155629e-02,\n",
       "         -4.55222558e-03,  1.08610895e-02, -2.10101381e-02,\n",
       "          3.67968194e-02,  1.63443618e-33, -7.54517764e-02,\n",
       "         -3.72056267e-03, -3.30698751e-02,  2.56306399e-02,\n",
       "         -2.14435961e-02,  4.71422914e-03, -1.03785815e-02,\n",
       "          8.87783691e-02, -2.98792738e-02,  2.86122411e-02,\n",
       "         -2.06554122e-02,  2.60108151e-02, -4.75581996e-02,\n",
       "         -4.81965672e-03,  6.41251877e-02, -5.69474474e-02,\n",
       "          6.49281666e-02, -1.38114810e-01,  5.93996793e-02,\n",
       "         -2.18336028e-03,  9.33864713e-02,  1.50043620e-02,\n",
       "          4.25813626e-03,  3.95708084e-02, -9.17580277e-02,\n",
       "          2.03484464e-02, -2.72361580e-02, -5.06099835e-02,\n",
       "         -1.51949422e-02,  2.40828786e-02,  3.83997746e-02,\n",
       "          3.40111740e-03, -7.48532340e-02, -8.21147785e-02,\n",
       "          4.00813594e-02,  2.33309455e-02, -6.00919314e-02,\n",
       "          5.34810647e-02, -1.25427181e-02,  2.78957821e-02,\n",
       "          3.23294699e-02,  3.38675343e-02, -4.77672927e-02,\n",
       "         -2.36974284e-02, -2.43656505e-02, -1.29131507e-02,\n",
       "         -3.73686664e-02, -7.31982430e-03,  1.32506102e-01,\n",
       "          1.91133581e-02,  6.31485060e-02, -1.37649015e-01,\n",
       "          2.43656486e-02, -8.76901597e-02,  1.23717906e-02,\n",
       "         -6.28773719e-02,  3.14051956e-02, -3.93760540e-02,\n",
       "         -4.52784076e-02,  7.16468468e-02,  2.08710600e-02,\n",
       "         -5.34138680e-02, -1.12921588e-01, -1.13987133e-01,\n",
       "          4.04967703e-02,  1.17938489e-01,  1.55126080e-02,\n",
       "         -2.58321203e-02,  1.85908768e-02, -1.60427969e-02,\n",
       "          4.09746319e-02, -2.11261562e-03, -8.62069502e-02,\n",
       "         -1.21933065e-01, -4.24475595e-03,  7.11902007e-02,\n",
       "         -5.73207811e-02,  2.77439039e-02,  4.37264591e-02,\n",
       "         -1.63011886e-02,  7.85956904e-03, -1.57871327e-04,\n",
       "          1.68785676e-02, -4.39538844e-02, -1.87198527e-03,\n",
       "         -2.03018021e-02, -6.98241405e-03,  1.07335925e-01,\n",
       "         -2.07657292e-02,  5.85735925e-02,  3.52960601e-02,\n",
       "          5.86682744e-02,  9.77534894e-03,  5.34883179e-02,\n",
       "          1.68914497e-02, -2.19188916e-08, -2.95723975e-02,\n",
       "         -3.72168981e-02, -3.74008156e-02,  9.28648859e-02,\n",
       "          5.08186184e-02,  4.79633361e-02, -2.35554837e-02,\n",
       "          4.03856412e-02,  1.42105699e-01,  2.74118278e-02,\n",
       "          4.89010587e-02, -3.25175896e-02, -3.06176599e-02,\n",
       "          7.27896094e-02,  9.97470841e-02,  8.45445041e-03,\n",
       "         -1.95387490e-02,  1.80566255e-02, -6.47272766e-02,\n",
       "         -7.73327202e-02, -5.81476651e-02,  5.27505018e-03,\n",
       "          9.64122042e-02, -1.43652126e-01,  1.17114596e-02,\n",
       "          1.02311354e-02, -1.01584278e-01,  2.90972497e-02,\n",
       "          2.15435028e-02,  6.96433932e-02, -4.70374711e-02,\n",
       "         -1.47143556e-02, -3.34438682e-02, -1.20040132e-02,\n",
       "         -5.77457547e-02,  3.00035393e-03, -1.48894787e-02,\n",
       "         -3.33925374e-02, -1.70185268e-02, -2.78972629e-02,\n",
       "          8.31555352e-02, -4.47435752e-02, -1.68391299e-02,\n",
       "          4.41731177e-02, -4.54828143e-02, -1.81344040e-02,\n",
       "         -8.59716758e-02,  4.02583554e-03, -3.17570455e-02,\n",
       "         -3.56782554e-03, -7.62897637e-03, -6.97090775e-02,\n",
       "         -1.55724427e-02,  1.00141108e-01,  5.05725779e-02,\n",
       "          3.08226924e-02, -1.35450782e-02,  2.54864655e-02,\n",
       "          5.19401506e-02,  1.28361396e-03,  6.60715923e-02,\n",
       "         -2.51783729e-02, -9.04075503e-02,  5.78886233e-02]]),\n",
       " 'documents': [\"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"],\n",
       " 'uris': None,\n",
       " 'included': ['embeddings', 'metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a4c9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[1.525183916091919, 1.754888653755188]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bdc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google is bringing Gemini to all older Pixel Buds',\n",
       " \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "result['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1044d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e96ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 384\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cbe2d",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b29b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0982f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6130e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16673d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c86941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   'The first Intel Battlmage GPU benchmarks have leaked']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.46601054072380066, 0.48678600788116455]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70061e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a68ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 1536\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66872a7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c04c9",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16137bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"GlobalEVOutlook2025.pdf\"\n",
    "documents = []\n",
    "page_nums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(file_path) as pdf:\n",
    "    for num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            documents.append(text)\n",
    "            page_nums.append(str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d1d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"traditional_rag\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2273128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=page_nums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb87904",
   "metadata": {},
   "source": [
    "**State Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcdcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570fcc",
   "metadata": {},
   "source": [
    "**RAG: Retrieve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d0d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:State, resource:Resource):\n",
    "    question = state[\"question\"]\n",
    "    collection:Collection = resource.vars.get(\"collection\")\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3,\n",
    "        include=['documents']\n",
    "    )\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    \n",
    "    return {\"documents\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60429f",
   "metadata": {},
   "source": [
    "**RAG: Augment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a17a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(state:State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    context = \"\\n\\n\".join(documents)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an assistant for question-answering tasks.\"),\n",
    "        UserMessage(\n",
    "            content=(\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \"\n",
    "                f\"\\n# Question: \\n-> {question} \"\n",
    "                f\"\\n# Context: \\n-> {context} \"\n",
    "                \"\\n# Answer: \"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e9be5",
   "metadata": {},
   "source": [
    "**RAG: Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ee61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State, resource:Resource):\n",
    "    llm:LLM = resource.vars.get(\"llm\")\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"answer\": ai_message.content, \n",
    "        \"messages\": state[\"messages\"] + [ai_message],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3c7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateMachine(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "entry = EntryPoint()\n",
    "retrieve_step = Step(\"retrieve\", retrieve)\n",
    "augment_step = Step(\"augment\", augment)\n",
    "generate_step = Step(\"generate\", generate)\n",
    "termination = Termination()\n",
    "        \n",
    "workflow.add_steps(\n",
    "    [\n",
    "        entry, \n",
    "        retrieve_step, \n",
    "        augment_step, \n",
    "        generate_step, \n",
    "        termination\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf846ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, retrieve_step)\n",
    "workflow.connect(retrieve_step, augment_step)\n",
    "workflow.connect(augment_step, generate_step)\n",
    "workflow.connect(generate_step, termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "039f9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a656f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = Resource(\n",
    "    vars = {\n",
    "        \"llm\": llm,\n",
    "        \"collection\": collection,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53eb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: State = {\n",
    "    \"question\": \"What was the number of electric car sales and their market share in Brazil in 2024?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e9954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state, resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9231fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024, Brazil had nearly 125,000 electric car sales, which represented a market share of 6.5%.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
